# Как работать с ELK-стеком

Этот проект служит учебным пособием по взаимодействию с ELK-стеком из типового
приложения на **Spring Boot**.

ELK - обозначает Elasticsearch, Logstash, Kibana. Эти приложения совместно
образуют экосистему, которую многие организации используют для журналирования.

Elasticsearch - основа всего, это хранилище данных, изначально спроектированное
как движок быстрого полнотекстового поиска. В настоящее время в Эластике можно
хранить всё, что угодно, включая логи.

Logstash - это коллектор логов. Это приложение служит для того, чтобы принимать
логи от других программ, анализировать, фильтровать, обогащать их и перенаправлять
в соответствующие поисковые индексы в Elasticsearch.

Kibana - это инструмент визуализации данных. Она способна отображать самые разные
данные, в частности, данные из индексов Elasticsearch.

## Как запустить?

Проект содержит две основные директории.

### docker

Здесь находится файл `docker-compose`, в котором уже всё сконфигурировано и подготовлено
для установки трёх контейнеров, для Elasticsearch, Logstash и Kibana, соответственно.

Также здесь размещён файл `pipeline/logstash.conf`, который содержит типовую конфигурацию
для маршрутизации логов в индексы. От каждого приложения лог пойдёт в собственный индекс.
Имя приложения должно быть добавлено в поле `application` у логирующего сообщения.

Примерно так выглядит эта конфигурация, не стесняйтесь её модифицировать, чтобы, к примеру
создавать индексы с другими названиями.


```
input {
    tcp {
        port => 5000
        type => syslog
        codec => json_lines
    }
}

filter {
    grok {
        match => [ "message", "%{GREEDYDATA}" ]
    }
}

output {
    stdout {
        codec => rubydebug
    }
    elasticsearch {
        hosts => [ "host.docker.internal:9200" ]
		user => "elastic"
		password => "elastic"
        index => "service-%{application}-%{+YYYY.MM.dd}"
    }
}
```

Перейдите в каталог `docker` и введите команду

```
docker-compose up -d
```

После этого Docker скачает все необходимые компоненты и поднимет три контейнера,
примерно через 5-10 секунд они будут готовы начать принимать логи.

### demo-application

А здесь находится простое приложение на **Spring Boot**, для которого настроено
журналирование с помощью библиотеки `log4j2`. Настройки логирования находятся в файле
`log4j2.xml`, который размещён в ресурсах приложения.

Обратите внимание, что в этих настройках указан аппендер (то есть то, куда будут
отправляться логи) типа `Socket`. Эта настройка обеспечивает взаимодействие демонстрационного
приложения с Logstash, который является коллектором логов. Приложение будет
генерировать логи в формате JSON и отправлять их по сети в указанный коллектор. В данном
случае это будет коллектор, работающий на той же машине, что и приложение.

### Как посмотреть логи?

Вам нужно запустить приложение `demo-application`, а затем перейти в Кибану по адресу
[http://localhost:5601](http://localhost:5601). Логин и пароль стандартные - elastic/elastic.
Вы можете настроить их по вашему желанию в файле `docker-compose`.

В Кибане вам нужно будет назначить Index Pattern. Для этого перейдите в левом меню
в раздел **Stack Management** -> **Index Patterns** и нажмите кнопку "Create new pattern".
Кибана продемонстрирует вам имеющиеся у нее индексы, если вы не видите ни одного, это может
означать, что вы еще не запускали приложение `demo-application`, либо что не все ваши контейнеры
работают правильно. Проверьте, что все три контейнера поднялись в Докере.

Скорее всего, вы увидите индекс с названием вроде service-demo-application-***.
Начните набирать его имя и укажите `service-demo-application*`. Такое имя паттерна 
создаст для вас представление, основанное на данных из этого конкретного поискового
индекса.

Далее выберите в левом меню пункт **Discover**, и вы увидите логи демонстрационного
приложения.